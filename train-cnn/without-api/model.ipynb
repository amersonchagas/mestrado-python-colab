{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe3IoZ338PDk"
      },
      "source": [
        "#Libs and datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WB0yRPKCbWya",
        "outputId": "488da5e0-95c8-4c6e-8528-bc2180714c6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dpSZclcA7rUy",
        "outputId": "e4092ab8-9da4-4efa-c7f2-15186e27c62e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=126dO4VNhLpYKT0TKp18RTAGjrHAl_ZpU\n",
            "To: /content/mnist.npz\n",
            "100% 55.4M/55.4M [00:00<00:00, 192MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16wlkaf6GCGX0aJTOtzDo0ypnhqYZ7GVM\n",
            "To: /content/kmnist.npz\n",
            "100% 55.4M/55.4M [00:00<00:00, 267MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XMH39lcD2bnwy4AW3S-4-0Ge7JIYw6CF\n",
            "To: /content/eurosat.npz\n",
            "100% 333M/333M [00:01<00:00, 167MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BsfU84WJMRRKG3wzRZG6KuCperlLrxHc\n",
            "To: /content/cifar10.npz\n",
            "100% 186M/186M [00:01<00:00, 152MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MvPjY4m58TW51NZbUIl5tRJbERKMnIk7\n",
            "To: /content/pathmnist.npz\n",
            "100% 206M/206M [00:01<00:00, 150MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=146WDl2VzVdLhnJl5JqYqKVyDPlDQoLDl\n",
            "To: /content/octmnist.npz\n",
            "100% 54.9M/54.9M [00:00<00:00, 147MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BIJFOn5ivB766qNIZdI2Owt8GAmpsmic\n",
            "To: /content/organmnist_axial.npz\n",
            "100% 38.2M/38.2M [00:00<00:00, 117MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=126dO4VNhLpYKT0TKp18RTAGjrHAl_ZpU -O mnist.npz\n",
        "!gdown https://drive.google.com/uc?id=16wlkaf6GCGX0aJTOtzDo0ypnhqYZ7GVM -O kmnist.npz\n",
        "!gdown https://drive.google.com/uc?id=1XMH39lcD2bnwy4AW3S-4-0Ge7JIYw6CF -O eurosat.npz\n",
        "!gdown https://drive.google.com/uc?id=1BsfU84WJMRRKG3wzRZG6KuCperlLrxHc -O cifar10.npz\n",
        "!gdown https://drive.google.com/uc?id=1MvPjY4m58TW51NZbUIl5tRJbERKMnIk7 -O pathmnist.npz\n",
        "!gdown https://drive.google.com/uc?id=146WDl2VzVdLhnJl5JqYqKVyDPlDQoLDl -O octmnist.npz\n",
        "!gdown https://drive.google.com/uc?id=1BIJFOn5ivB766qNIZdI2Owt8GAmpsmic -O organmnist_axial.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zHwZmGUNbTRf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import callbacks, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications import InceptionV3, ResNet50V2, EfficientNetB1, DenseNet169\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Lambda, Input\n",
        "from tensorflow.image import resize\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import friedmanchisquare, rankdata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re, os, time, requests\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhvasHsa8VPv"
      },
      "source": [
        "#Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UXE-7P_oKP3G"
      },
      "outputs": [],
      "source": [
        "DATASETS = {\n",
        "    'cifar10': {\n",
        "        'shape': (32, 32, 3),\n",
        "        'classes': 10,\n",
        "        'phenotypes': ['(((conv*3)bnorm-pool-dropout)*3)fc*1*256*lr-0.001'],\n",
        "    },\n",
        "    'mnist': {\n",
        "        'shape': (28, 28, 1),\n",
        "        'classes': 10,\n",
        "        'phenotypes': ['(((conv*3)bnorm-pool-dropout)*3)fc*1*256*lr-0.001'],\n",
        "    },\n",
        "    'eurosat': {\n",
        "        'shape': (64, 64, 3),\n",
        "        'classes': 10,\n",
        "        'phenotypes': ['(((conv*3)bnorm-pool-dropout)*3)fc*1*256*lr-0.001'],\n",
        "    },\n",
        "}\n",
        "NUM_TRAINING = 3\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 70"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKmIcKBj8eO-"
      },
      "source": [
        "#Factories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JKOm_msFbalE"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_name):\n",
        "\n",
        "  shape = DATASETS[dataset_name]['shape']\n",
        "  dataset = np.load('%s.npz' % dataset_name, allow_pickle=True)\n",
        "\n",
        "  if dataset_name == 'eurosat':\n",
        "      \n",
        "    print('eurosat')\n",
        "    \n",
        "    train = dataset['train'].tolist()\n",
        "\n",
        "    train_images, train_labels = train['image'], train['label']\n",
        "\n",
        "    train_images = train_images.reshape((train_images.shape[0], *shape))\n",
        "    train_images = train_images.astype(\"float\") / 255.0\n",
        "\n",
        "    train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
        "    validation_images, test_images, validation_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "  elif dataset_name in ['pathmnist', 'octmnist', 'organmnist_axial']:\n",
        "      \n",
        "    print('medmnist:', dataset_name)\n",
        "    \n",
        "    train_images = dataset['train_images']\n",
        "    validation_images = dataset['val_images']\n",
        "    test_images = dataset['test_images']\n",
        "    train_labels = dataset['train_labels']\n",
        "    validation_labels = dataset['val_labels']\n",
        "    test_labels = dataset['test_labels']\n",
        "\n",
        "    if shape[2] == 1:\n",
        "      train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "      validation_images = validation_images.reshape((validation_images.shape[0], 28, 28, 1))\n",
        "      test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
        "\n",
        "    train_images = train_images.astype(\"float\") / 255.0\n",
        "    test_images = test_images.astype(\"float\") / 255.0\n",
        "    validation_images = validation_images.astype(\"float\") / 255.0\n",
        "\n",
        "  else:\n",
        "      \n",
        "    print('outros:', dataset_name)\n",
        "    \n",
        "    train = dataset['train'].tolist()\n",
        "    test = dataset['test'].tolist()\n",
        "\n",
        "    train_images, test_images, train_labels, test_labels = train['image'], test['image'], train['label'], test['label']\n",
        "\n",
        "    train_images = train_images.reshape((train_images.shape[0], *shape))\n",
        "    train_images = train_images.astype(\"float\") / 255.0\n",
        "\n",
        "    test_images = test_images.reshape((test_images.shape[0], *shape))\n",
        "    test_images = test_images.astype(\"float\") / 255.0\n",
        "\n",
        "    validation_images, test_images, validation_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "  lb = LabelBinarizer()\n",
        "  train_labels = lb.fit_transform(train_labels)\n",
        "  validation_labels = lb.transform(validation_labels)\n",
        "  test_labels = lb.transform(test_labels)\n",
        "\n",
        "  dataset.close()\n",
        "\n",
        "  return train_images, train_labels, validation_images, validation_labels, test_images, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "41QD3TOGjZiC"
      },
      "outputs": [],
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "  \n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "  return f1_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kQEKzjs78zaA"
      },
      "outputs": [],
      "source": [
        "def build_model(dataset, phenotype):\n",
        "\n",
        "    dataset_shape = DATASETS[dataset]['shape']\n",
        "    dataset_classes = DATASETS[dataset]['classes']\n",
        "\n",
        "    nconv, npool, nfc, nfcneuron = [int(i) for i in re.findall('\\d+', phenotype.split('lr-')[0])]\n",
        "    has_dropout = 'dropout' in phenotype\n",
        "    has_batch_normalization = 'bnorm' in phenotype\n",
        "    has_pool = 'pool' in phenotype\n",
        "    learning_rate = float(phenotype.split('lr-')[1])\n",
        "\n",
        "    # number of filters\n",
        "    filter_size = 32\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=dataset_shape))\n",
        "\n",
        "    # Pooling\n",
        "    for i in range(npool):\n",
        "\n",
        "        # Convolutions\n",
        "        for j in range(nconv):\n",
        "\n",
        "            model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "            # Duplicate number of filters for each two convolutions\n",
        "            if (((i + j) % 2) == 1): filter_size = filter_size * 2\n",
        "\n",
        "            # Add batch normalization\n",
        "            if has_batch_normalization:\n",
        "                model.add(layers.BatchNormalization())\n",
        "\n",
        "        # Add pooling\n",
        "        if has_pool:\n",
        "            model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "            # Add dropout\n",
        "            if has_dropout:\n",
        "                model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # fully connected\n",
        "    for i in range(nfc):\n",
        "        model.add(layers.Dense(nfcneuron))\n",
        "        model.add(layers.Activation('relu'))\n",
        "\n",
        "    if has_dropout:\n",
        "        model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(dataset_classes, activation='softmax'))\n",
        "\n",
        "    opt = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    return model, opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-KjZKEH8j3a"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O6eGNXPReUoX"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataset):\n",
        "\n",
        "  train_images, train_labels, validation_images, \\\n",
        "    validation_labels, test_images, test_labels = load_dataset(dataset)\n",
        "\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(BATCH_SIZE, drop_remainder=True)\n",
        "  validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels)).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "  accuracies, f1_scores = [], []\n",
        "\n",
        "  for i in range(NUM_TRAINING):\n",
        "\n",
        "    print('Training %s of %s' % (i + 1, NUM_TRAINING))\n",
        "\n",
        "    history = model.fit(train_ds,\n",
        "            epochs=EPOCHS, \n",
        "            validation_data=validation_ds,\n",
        "            verbose=1)\n",
        "\n",
        "    loss, accuracy, f1_score = model.evaluate(test_images, test_labels, verbose=1)\n",
        "\n",
        "    print(accuracy, f1_score)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    f1_scores.append(f1_score)\n",
        "\n",
        "  return {\n",
        "      'accuracy': np.mean(accuracies),\n",
        "      'accuracy_sd': np.std(accuracies),\n",
        "      'f1_score': np.mean(f1_scores),\n",
        "      'f1_score_sd': np.std(f1_scores),\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UnEp86OdlYRX",
        "outputId": "f9a46c05-bfbe-4aef-e536-c69f17455b93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.73.2:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.73.2:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JwD-VuR3KuI",
        "scrolled": true,
        "outputId": "6bd19ff5-431f-422f-fd19-e85f4b09a230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET: cifar10\n",
            "PHENOTYPE: (((conv*3)bnorm-pool-dropout)*3)fc*1*256*lr-0.001\n",
            "Building model.\n",
            "Model created.\n",
            "Begining training...\n",
            "outros: cifar10\n",
            "Training 1 of 3\n",
            "Epoch 1/70\n",
            "390/390 [==============================] - 95s 236ms/step - loss: 1.8175 - accuracy: 0.3691 - f1_score: 0.2407 - val_loss: 2.4535 - val_accuracy: 0.2563 - val_f1_score: 0.1809\n",
            "Epoch 2/70\n",
            "390/390 [==============================] - 94s 238ms/step - loss: 1.2548 - accuracy: 0.5608 - f1_score: 0.5071 - val_loss: 1.0007 - val_accuracy: 0.6502 - val_f1_score: 0.6309\n",
            "Epoch 3/70\n",
            "390/390 [==============================] - 94s 238ms/step - loss: 1.0252 - accuracy: 0.6505 - f1_score: 0.6225 - val_loss: 0.8926 - val_accuracy: 0.6859 - val_f1_score: 0.6752\n",
            "Epoch 4/70\n",
            "390/390 [==============================] - 94s 238ms/step - loss: 0.8782 - accuracy: 0.7011 - f1_score: 0.6892 - val_loss: 0.8703 - val_accuracy: 0.7045 - val_f1_score: 0.6947\n",
            "Epoch 5/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.8753 - accuracy: 0.7126 - f1_score: 0.7024 - val_loss: 1.3561 - val_accuracy: 0.5500 - val_f1_score: 0.5618\n",
            "Epoch 6/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.7983 - accuracy: 0.7385 - f1_score: 0.7290 - val_loss: 0.6632 - val_accuracy: 0.7753 - val_f1_score: 0.7750\n",
            "Epoch 7/70\n",
            "390/390 [==============================] - 94s 238ms/step - loss: 0.6410 - accuracy: 0.7901 - f1_score: 0.7836 - val_loss: 0.6419 - val_accuracy: 0.7859 - val_f1_score: 0.7860\n",
            "Epoch 8/70\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6340 - accuracy: 0.7910 - f1_score: 0.7894 - val_loss: 0.7310 - val_accuracy: 0.7717 - val_f1_score: 0.7673\n",
            "Epoch 9/70\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.5899 - accuracy: 0.8057 - f1_score: 0.8033 - val_loss: 0.5598 - val_accuracy: 0.8112 - val_f1_score: 0.8150\n",
            "Epoch 10/70\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 0.5626 - accuracy: 0.8125 - f1_score: 0.8133 - val_loss: 1.2955 - val_accuracy: 0.6042 - val_f1_score: 0.6021\n",
            "Epoch 11/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.5046 - accuracy: 0.8320 - f1_score: 0.8322 - val_loss: 0.5601 - val_accuracy: 0.8243 - val_f1_score: 0.8262\n",
            "Epoch 12/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.3888 - accuracy: 0.8690 - f1_score: 0.8695 - val_loss: 0.5648 - val_accuracy: 0.8346 - val_f1_score: 0.8411\n",
            "Epoch 13/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.3382 - accuracy: 0.8869 - f1_score: 0.8871 - val_loss: 0.5685 - val_accuracy: 0.8359 - val_f1_score: 0.8388\n",
            "Epoch 14/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.3040 - accuracy: 0.8974 - f1_score: 0.8981 - val_loss: 0.5583 - val_accuracy: 0.8390 - val_f1_score: 0.8456\n",
            "Epoch 15/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.2748 - accuracy: 0.9062 - f1_score: 0.9061 - val_loss: 0.5578 - val_accuracy: 0.8473 - val_f1_score: 0.8493\n",
            "Epoch 16/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.2525 - accuracy: 0.9142 - f1_score: 0.9152 - val_loss: 0.5881 - val_accuracy: 0.8391 - val_f1_score: 0.8442\n",
            "Epoch 17/70\n",
            "390/390 [==============================] - 94s 238ms/step - loss: 0.2220 - accuracy: 0.9242 - f1_score: 0.9254 - val_loss: 0.5901 - val_accuracy: 0.8414 - val_f1_score: 0.8444\n",
            "Epoch 18/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.2120 - accuracy: 0.9292 - f1_score: 0.9291 - val_loss: 0.5845 - val_accuracy: 0.8459 - val_f1_score: 0.8506\n",
            "Epoch 19/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.2014 - accuracy: 0.9320 - f1_score: 0.9321 - val_loss: 0.6389 - val_accuracy: 0.8407 - val_f1_score: 0.8452\n",
            "Epoch 20/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.1838 - accuracy: 0.9377 - f1_score: 0.9382 - val_loss: 0.6278 - val_accuracy: 0.8550 - val_f1_score: 0.8578\n",
            "Epoch 21/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1578 - accuracy: 0.9466 - f1_score: 0.9466 - val_loss: 0.6719 - val_accuracy: 0.8535 - val_f1_score: 0.8562\n",
            "Epoch 22/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1675 - accuracy: 0.9458 - f1_score: 0.9463 - val_loss: 0.6519 - val_accuracy: 0.8502 - val_f1_score: 0.8513\n",
            "Epoch 23/70\n",
            "390/390 [==============================] - 95s 241ms/step - loss: 0.1478 - accuracy: 0.9513 - f1_score: 0.9520 - val_loss: 0.7185 - val_accuracy: 0.8489 - val_f1_score: 0.8507\n",
            "Epoch 24/70\n",
            "390/390 [==============================] - 95s 241ms/step - loss: 0.1315 - accuracy: 0.9564 - f1_score: 0.9570 - val_loss: 0.6637 - val_accuracy: 0.8531 - val_f1_score: 0.8559\n",
            "Epoch 25/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1300 - accuracy: 0.9576 - f1_score: 0.9574 - val_loss: 0.7184 - val_accuracy: 0.8487 - val_f1_score: 0.8516\n",
            "Epoch 26/70\n",
            "390/390 [==============================] - 95s 242ms/step - loss: 0.1258 - accuracy: 0.9601 - f1_score: 0.9601 - val_loss: 0.7385 - val_accuracy: 0.8463 - val_f1_score: 0.8481\n",
            "Epoch 27/70\n",
            "390/390 [==============================] - 95s 241ms/step - loss: 0.1156 - accuracy: 0.9627 - f1_score: 0.9625 - val_loss: 0.7679 - val_accuracy: 0.8435 - val_f1_score: 0.8472\n",
            "Epoch 28/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1111 - accuracy: 0.9634 - f1_score: 0.9636 - val_loss: 0.6713 - val_accuracy: 0.8657 - val_f1_score: 0.8677\n",
            "Epoch 29/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1006 - accuracy: 0.9683 - f1_score: 0.9685 - val_loss: 0.7802 - val_accuracy: 0.8601 - val_f1_score: 0.8608\n",
            "Epoch 30/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1046 - accuracy: 0.9666 - f1_score: 0.9667 - val_loss: 0.7449 - val_accuracy: 0.8582 - val_f1_score: 0.8599\n",
            "Epoch 31/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.0976 - accuracy: 0.9688 - f1_score: 0.9689 - val_loss: 0.8398 - val_accuracy: 0.8451 - val_f1_score: 0.8485\n",
            "Epoch 32/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.1026 - accuracy: 0.9686 - f1_score: 0.9684 - val_loss: 0.7449 - val_accuracy: 0.8575 - val_f1_score: 0.8605\n",
            "Epoch 33/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.0854 - accuracy: 0.9729 - f1_score: 0.9733 - val_loss: 0.8090 - val_accuracy: 0.8572 - val_f1_score: 0.8590\n",
            "Epoch 34/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.0821 - accuracy: 0.9738 - f1_score: 0.9740 - val_loss: 0.7570 - val_accuracy: 0.8459 - val_f1_score: 0.8496\n",
            "Epoch 35/70\n",
            "390/390 [==============================] - 95s 241ms/step - loss: 0.0931 - accuracy: 0.9714 - f1_score: 0.9714 - val_loss: 0.8072 - val_accuracy: 0.8514 - val_f1_score: 0.8551\n",
            "Epoch 36/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.0775 - accuracy: 0.9751 - f1_score: 0.9752 - val_loss: 0.9392 - val_accuracy: 0.8499 - val_f1_score: 0.8513\n",
            "Epoch 37/70\n",
            "390/390 [==============================] - 94s 240ms/step - loss: 0.0740 - accuracy: 0.9766 - f1_score: 0.9767 - val_loss: 0.7325 - val_accuracy: 0.8682 - val_f1_score: 0.8692\n",
            "Epoch 38/70\n",
            "390/390 [==============================] - 94s 239ms/step - loss: 0.0715 - accuracy: 0.9780 - f1_score: 0.9780 - val_loss: 0.7517 - val_accuracy: 0.8658 - val_f1_score: 0.8675\n",
            "Epoch 39/70\n",
            "239/390 [=================>............] - ETA: 35s - loss: 0.0690 - accuracy: 0.9783 - f1_score: 0.9780"
          ]
        }
      ],
      "source": [
        "for dataset in DATASETS:\n",
        "\n",
        "  for phenotype in DATASETS[dataset]['phenotypes']:\n",
        "\n",
        "    print('DATASET:', dataset)\n",
        "    print('PHENOTYPE:', phenotype)\n",
        "\n",
        "    print('Building model.')\n",
        "\n",
        "    model, opt = build_model(dataset, phenotype)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', f1_score])\n",
        "    # model.summary()\n",
        "\n",
        "    print('Model created.')\n",
        "\n",
        "    print('Begining training...')\n",
        "\n",
        "    fitness = train_model(model, dataset)\n",
        "\n",
        "    print('FITNESS:', fitness)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "analise_amerson.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}