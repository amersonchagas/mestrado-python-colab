{"cells":[{"cell_type":"markdown","metadata":{"id":"Qe3IoZ338PDk"},"source":["#Libs and datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7763,"status":"ok","timestamp":1644342115145,"user":{"displayName":"Amerson Chagas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZa0sj34fT4KS50sfZ_0Mv6sPOxixNpwn8YaRvkw=s64","userId":"13028379379499693318"},"user_tz":180},"id":"WB0yRPKCbWya","outputId":"921eb5b3-ccd0-46a8-a4f1-c5a4401552ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.4.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Requirement already satisfied: orange3 in /usr/local/lib/python3.7/dist-packages (3.31.1)\n","Requirement already satisfied: PyQt5!=5.15.1,>=5.12 in /usr/local/lib/python3.7/dist-packages (from orange3) (5.15.6)\n","Requirement already satisfied: serverfiles in /usr/local/lib/python3.7/dist-packages (from orange3) (0.3.1)\n","Requirement already satisfied: keyring in /usr/local/lib/python3.7/dist-packages (from orange3) (23.5.0)\n","Requirement already satisfied: bottleneck>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.3.2)\n","Requirement already satisfied: xlrd>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.1.0)\n","Requirement already satisfied: python-louvain>=0.13 in /usr/local/lib/python3.7/dist-packages (from orange3) (0.16)\n","Requirement already satisfied: pyqtgraph>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from orange3) (0.12.3)\n","Requirement already satisfied: pip>=9.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (21.1.3)\n","Requirement already satisfied: PyQtWebEngine>=5.12 in /usr/local/lib/python3.7/dist-packages (from orange3) (5.15.5)\n","Requirement already satisfied: keyrings.alt in /usr/local/lib/python3.7/dist-packages (from orange3) (4.1.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from orange3) (2.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from orange3) (2.23.0)\n","Requirement already satisfied: AnyQt>=0.0.11 in /usr/local/lib/python3.7/dist-packages (from orange3) (0.0.13)\n","Requirement already satisfied: orange-canvas-core<0.2a,>=0.1.24 in /usr/local/lib/python3.7/dist-packages (from orange3) (0.1.24)\n","Requirement already satisfied: orange-widget-base>=4.16.1 in /usr/local/lib/python3.7/dist-packages (from orange3) (4.16.1)\n","Requirement already satisfied: qtconsole>=4.7.2 in /usr/local/lib/python3.7/dist-packages (from orange3) (5.2.2)\n","Requirement already satisfied: httpx<0.20,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (0.19.0)\n","Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from orange3) (3.0.4)\n","Requirement already satisfied: pygments>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (2.11.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from orange3) (3.13)\n","Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (from orange3) (3.0.2)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from orange3) (3.0.9)\n","Requirement already satisfied: baycomp>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.0.2)\n","Requirement already satisfied: scikit-learn!=1.0.0,>0.23.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.0.2)\n","Requirement already satisfied: joblib>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.1.0)\n","Requirement already satisfied: openTSNE>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from orange3) (0.6.1)\n","Requirement already satisfied: setuptools>=36.3 in /usr/local/lib/python3.7/dist-packages (from orange3) (57.4.0)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (3.2.2)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.19.5)\n","Requirement already satisfied: scipy>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.4.1)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from orange3) (1.3.5)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from httpx<0.20,>=0.14.0->orange3) (2.0.11)\n","Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx<0.20,>=0.14.0->orange3) (1.5.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx<0.20,>=0.14.0->orange3) (2021.10.8)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx<0.20,>=0.14.0->orange3) (1.2.0)\n","Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from httpx<0.20,>=0.14.0->orange3) (0.13.7)\n","Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx<0.20,>=0.14.0->orange3) (0.12.0)\n","Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx<0.20,>=0.14.0->orange3) (3.5.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20,>=0.14.0->orange3) (3.10.0.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20,>=0.14.0->orange3) (2.10)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->orange3) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->orange3) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->orange3) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->orange3) (3.0.7)\n","Requirement already satisfied: docutils in /usr/local/lib/python3.7/dist-packages (from orange-canvas-core<0.2a,>=0.1.24->orange3) (0.17.1)\n","Requirement already satisfied: qasync in /usr/local/lib/python3.7/dist-packages (from orange-canvas-core<0.2a,>=0.1.24->orange3) (0.23.0)\n","Requirement already satisfied: dictdiffer in /usr/local/lib/python3.7/dist-packages (from orange-canvas-core<0.2a,>=0.1.24->orange3) (0.9.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from orange-canvas-core<0.2a,>=0.1.24->orange3) (4.10.1)\n","Requirement already satisfied: cachecontrol[filecache] in /usr/local/lib/python3.7/dist-packages (from orange-canvas-core<0.2a,>=0.1.24->orange3) (0.12.10)\n","Requirement already satisfied: commonmark>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from orange-canvas-core<0.2a,>=0.1.24->orange3) (0.9.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->orange3) (2018.9)\n","Requirement already satisfied: PyQt5-Qt5>=5.15.2 in /usr/local/lib/python3.7/dist-packages (from PyQt5!=5.15.1,>=5.12->orange3) (5.15.2)\n","Requirement already satisfied: PyQt5-sip<13,>=12.8 in /usr/local/lib/python3.7/dist-packages (from PyQt5!=5.15.1,>=5.12->orange3) (12.9.1)\n","Requirement already satisfied: PyQtWebEngine-Qt5>=5.15.2 in /usr/local/lib/python3.7/dist-packages (from PyQtWebEngine>=5.12->orange3) (5.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->orange3) (1.15.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (0.2.0)\n","Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (5.3.5)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (5.1.1)\n","Requirement already satisfied: ipykernel>=4.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (4.10.1)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (22.3.0)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (2.0.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from qtconsole>=4.7.2->orange3) (4.9.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.1->qtconsole>=4.7.2->orange3) (5.5.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (1.0.18)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.2.5)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=1.0.0,>0.23.0->orange3) (3.1.0)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from cachecontrol[filecache]->orange-canvas-core<0.2a,>=0.1.24->orange3) (1.0.3)\n","Requirement already satisfied: lockfile>=0.9 in /usr/local/lib/python3.7/dist-packages (from cachecontrol[filecache]->orange-canvas-core<0.2a,>=0.1.24->orange3) (0.12.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->orange-canvas-core<0.2a,>=0.1.24->orange3) (3.7.0)\n","Requirement already satisfied: jeepney>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from keyring->orange3) (0.7.1)\n","Requirement already satisfied: SecretStorage>=3.2 in /usr/local/lib/python3.7/dist-packages (from keyring->orange3) (3.3.1)\n","Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from SecretStorage>=3.2->keyring->orange3) (36.0.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring->orange3) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring->orange3) (2.21)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl->orange3) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=4.0.0->ipykernel>=4.1->qtconsole>=4.7.2->orange3) (0.7.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy->qtconsole>=4.7.2->orange3) (21.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->orange3) (1.24.3)\n"]}],"source":["!pip install gdown\n","!pip install orange3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20843,"status":"ok","timestamp":1644342135985,"user":{"displayName":"Amerson Chagas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZa0sj34fT4KS50sfZ_0Mv6sPOxixNpwn8YaRvkw=s64","userId":"13028379379499693318"},"user_tz":180},"id":"dpSZclcA7rUy","outputId":"727cf758-06c5-442c-d987-1977372635ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=126dO4VNhLpYKT0TKp18RTAGjrHAl_ZpU\n","To: /content/mnist.npz\n","100% 55.4M/55.4M [00:00<00:00, 241MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=16wlkaf6GCGX0aJTOtzDo0ypnhqYZ7GVM\n","To: /content/kmnist.npz\n","100% 55.4M/55.4M [00:00<00:00, 121MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1XMH39lcD2bnwy4AW3S-4-0Ge7JIYw6CF\n","To: /content/eurosat.npz\n","100% 333M/333M [00:03<00:00, 108MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1BsfU84WJMRRKG3wzRZG6KuCperlLrxHc\n","To: /content/cifar10.npz\n","100% 186M/186M [00:01<00:00, 124MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1MvPjY4m58TW51NZbUIl5tRJbERKMnIk7\n","To: /content/pathmnist.npz\n","100% 206M/206M [00:01<00:00, 104MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=146WDl2VzVdLhnJl5JqYqKVyDPlDQoLDl\n","To: /content/octmnist.npz\n","100% 54.9M/54.9M [00:00<00:00, 128MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1BIJFOn5ivB766qNIZdI2Owt8GAmpsmic\n","To: /content/organmnist_axial.npz\n","100% 38.2M/38.2M [00:00<00:00, 89.0MB/s]\n"]}],"source":["!gdown https://drive.google.com/uc?id=126dO4VNhLpYKT0TKp18RTAGjrHAl_ZpU -O mnist.npz\n","!gdown https://drive.google.com/uc?id=16wlkaf6GCGX0aJTOtzDo0ypnhqYZ7GVM -O kmnist.npz\n","!gdown https://drive.google.com/uc?id=1XMH39lcD2bnwy4AW3S-4-0Ge7JIYw6CF -O eurosat.npz\n","!gdown https://drive.google.com/uc?id=1BsfU84WJMRRKG3wzRZG6KuCperlLrxHc -O cifar10.npz\n","!gdown https://drive.google.com/uc?id=1MvPjY4m58TW51NZbUIl5tRJbERKMnIk7 -O pathmnist.npz\n","!gdown https://drive.google.com/uc?id=146WDl2VzVdLhnJl5JqYqKVyDPlDQoLDl -O octmnist.npz\n","!gdown https://drive.google.com/uc?id=1BIJFOn5ivB766qNIZdI2Owt8GAmpsmic -O organmnist_axial.npz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHwZmGUNbTRf"},"outputs":[],"source":["from tensorflow.keras import callbacks, optimizers\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.applications import InceptionV3, ResNet50V2, EfficientNetB1, DenseNet169\n","from tensorflow.keras import models, layers, optimizers\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Lambda, Input\n","from tensorflow.image import resize\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from Orange.evaluation import compute_CD, graph_ranks\n","from scipy.stats import friedmanchisquare, rankdata\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import re, os, time, requests\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"EhvasHsa8VPv"},"source":["#Configs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXE-7P_oKP3G"},"outputs":[],"source":["DATASETS = {\n","    'cifar10': {\n","        'shape': (32, 32, 3),\n","        'classes': 10,\n","        'proposal': '3(Conv BNorm),(Conv ),(Conv BNorm),(MaxPool Dropout),(Flatten),(Fc 1 512 Dropout),(Softmax),(Lr 0.001)',\n","        'De Lima': 'Conv2D 128 5 tanh , MaxPooling2D 6 same , Dropout 0.2 , Dense 32 , Dense 128 ,',\n","        'Diniz': '(((conv*1)pool)*3)fc*0',\n","        'Silva': '(((conv*3)bnorm-pool-dropout)*3)fc*1*256*lr-0.001',\n","        'Assuncao': 'layer:conv 128 2 1 same relu 0 1 1, layer:conv 256 3 1 same sigmoid 0 0 0, layer:pool-max 5 2 same, layer:conv 64 4 1 same sigmoid 1 1 1, layer:pool-avg 3 1 valid, layer:conv 256 5 1 same relu 0 0 1, layer:fc linear 1024 1, layer:fc linear 128 0, layer:fc relu 512 1, layer:fc sigmoid 128 0, layer:fc softmax, learning:gradient_descent 0.1'\n","    },\n","    'mnist': {\n","        'shape': (28, 28, 1),\n","        'classes': 10,\n","        'proposal': '3(Conv BNorm),(Conv ),(Conv BNorm),(MaxPool Dropout),(Flatten),(Fc 1 64 Dropout),(Softmax),(Lr 0.0001)',\n","        'De Lima': 'Conv2D 16 7 tanh , MaxPooling2D 2 same , Conv2D 32 3 elu , Dropout 0.6 , Dense 64 ,',\n","        'Diniz': '(((conv*1)pool)*2)fc*0',\n","        'Silva': '(((conv*2)bnorm-pool-dropout)*2)fc*2*512*lr-0.0001',\n","        'Assuncao': 'layer:conv 32 2 1 same relu 0 1 1, layer:conv 128 3 1 same linear 0 1 0, layer:pool-max 5 2 same, layer:conv 256 3 1 same linear 1 0 0, layer:pool-max 4 1 valid, layer:conv 256 5 2 valid linear 1 1 1, layer:fc linear 256 1, layer:fc relu 1024 1, layer:fc linear 1024 1, layer:fc linear 256 0, layer:fc linear 2048 1, layer:fc linear 2048 1, layer:fc sigmoid 1024 1, layer:fc softmax, learning:gradient_descent 0.1'\n","    },\n","    'eurosat': {\n","        'shape': (64, 64, 3),\n","        'classes': 10,\n","        'proposal': '3(Conv ),(Conv BNorm),(Conv ),(MaxPool Dropout),(Flatten),(Fc 1 128 Dropout),(Softmax),(Lr 0.0001)',\n","        'De Lima': 'Conv2D 64 3 selu , MaxPooling2D 4 same , Conv2D 64 3 selu ,  MaxPooling2D 6 same ,  AveragePooling2D 4 same , MaxPooling2D 4 same ,  Dropout 0.1 , Dense 32 ,',\n","        'Diniz': '(((conv*1)pool)*3)fc*2',\n","        'Silva': '(((conv*3)bnorm-pool-)*3)fc*0*64*lr-0.001',\n","        'Assuncao': 'layer:conv 32 2 1 same relu 1 1 1, layer:pool-max 4 1 same, layer:conv 128 1 2 same relu 1 0 1, layer:conv 128 5 1 same relu 0 1 1, layer:conv 128 5 2 same relu 1 0 1, layer:pool-max 5 3 valid, layer:pool-avg 2 1 valid, layer:fc sigmoid 128 0, layer:fc sigmoid 1024 1, layer:fc softmax, learning:gradient_descent 0.1'\n","    },\n","}\n","CNNS = ['Silva']\n","PAPER_NAME = 'wcci'\n","NUM_SAMPLES = 20\n","METRICS_URL = 'https://c50b-2804-954-3da-da00-406a-9e5a-8132-20ac.ngrok.io/api/analysis/'"]},{"cell_type":"markdown","metadata":{"id":"oKmIcKBj8eO-"},"source":["#Factories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKOm_msFbalE"},"outputs":[],"source":["def load_dataset(dataset_name):\n","\n","  shape = DATASETS[dataset_name]['shape']\n","  dataset = np.load('%s.npz' % dataset_name, allow_pickle=True)\n","\n","  if dataset_name == 'eurosat':\n","      \n","    print('eurosat')\n","    \n","    train = dataset['train'].tolist()\n","\n","    train_images, train_labels = train['image'], train['label']\n","\n","    train_images = train_images.reshape((train_images.shape[0], *shape))\n","    train_images = train_images.astype(\"float\") / 255.0\n","\n","    train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n","    validation_images, test_images, validation_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2, random_state=42)\n","\n","  elif dataset_name in ['pathmnist', 'octmnist', 'organmnist_axial']:\n","      \n","    print('medmnist:', dataset_name)\n","    \n","    train_images = dataset['train_images']\n","    validation_images = dataset['val_images']\n","    test_images = dataset['test_images']\n","    train_labels = dataset['train_labels']\n","    validation_labels = dataset['val_labels']\n","    test_labels = dataset['test_labels']\n","\n","    if shape[2] == 1:\n","      train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n","      validation_images = validation_images.reshape((validation_images.shape[0], 28, 28, 1))\n","      test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n","\n","    train_images = train_images.astype(\"float\") / 255.0\n","    test_images = test_images.astype(\"float\") / 255.0\n","    validation_images = validation_images.astype(\"float\") / 255.0\n","\n","  else:\n","      \n","    print('outros:', dataset_name)\n","    \n","    train = dataset['train'].tolist()\n","    test = dataset['test'].tolist()\n","\n","    train_images, test_images, train_labels, test_labels = train['image'], test['image'], train['label'], test['label']\n","\n","    train_images = train_images.reshape((train_images.shape[0], *shape))\n","    train_images = train_images.astype(\"float\") / 255.0\n","\n","    test_images = test_images.reshape((test_images.shape[0], *shape))\n","    test_images = test_images.astype(\"float\") / 255.0\n","\n","    validation_images, test_images, validation_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2, random_state=42)\n","\n","  lb = LabelBinarizer()\n","  train_labels = lb.fit_transform(train_labels)\n","  validation_labels = lb.transform(validation_labels)\n","  test_labels = lb.transform(test_labels)\n","\n","  dataset.close()\n","\n","  return train_images, train_labels, validation_images, validation_labels, test_images, test_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41QD3TOGjZiC"},"outputs":[],"source":["def f1_score(y_true, y_pred):\n","  \n","  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","  precision = true_positives / (predicted_positives + K.epsilon())\n","  recall = true_positives / (possible_positives + K.epsilon())\n","  f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","  return f1_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tkzRA2jI6rZY"},"outputs":[],"source":["def build_assuncao_model(dataset):\n","\n","    phenotype = DATASETS[dataset]['Assuncao']\n","    dataset_shape = DATASETS[dataset]['shape']\n","    dataset_classes = DATASETS[dataset]['classes']\n","\n","    model = models.Sequential()\n","    model.add(layers.InputLayer(input_shape=dataset_shape))\n","\n","    learning_rate = None\n","    parts = phenotype.split(', ')\n","\n","    for part in parts:\n","\n","        sections = part.split(' ')\n","\n","        if 'layer:conv' in part:\n","            padding = sections[4]\n","            activation = sections[5]\n","            num_filters, filter_shape, stride, bias, bnorm, merge = [int(i) for i in re.findall('\\d+', part)]\n","            model.add(layers.Conv2D(num_filters, (filter_shape, filter_shape), strides=(stride, stride), use_bias=bool(bias), activation=activation, padding=padding))\n","            if bnorm:\n","                model.add(layers.BatchNormalization())\n","        elif 'layer:pool' in part:\n","            padding = sections[3]\n","            kernel_size, stride = [int(i) for i in re.findall('\\d+', part)]\n","            if 'avg' in part:\n","                model.add(layers.AveragePooling2D(pool_size=(kernel_size, kernel_size), strides=(stride, stride), padding=padding))\n","            elif 'max' in part:\n","                model.add(layers.MaxPooling2D(pool_size=(kernel_size, kernel_size), strides=(stride, stride), padding=padding))\n","        elif 'layer:fc' in part:\n","            if 'Flatten' not in ''.join([str(l.__class__) for l in model.layers]):\n","                model.add(layers.Flatten())\n","            activation = sections[1]\n","            if 'softmax' in activation:\n","                model.add(layers.Dense(dataset_classes, activation=activation))\n","            else:\n","                num_units, bias = [int(i) for i in re.findall('\\d+', part)]\n","                model.add(layers.Dense(num_units, activation=activation, use_bias=bool(bias)))\n","        elif 'learning' in part:\n","            learning_rate = float(sections[1])\n","\n","    opt = optimizers.SGD(learning_rate=learning_rate)\n","\n","    return model, opt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mtu5VNU07NjI"},"outputs":[],"source":["def build_delima_model(dataset):\n","\n","    phenotype = DATASETS[dataset]['De Lima']\n","    dataset_shape = DATASETS[dataset]['shape']\n","    dataset_classes = DATASETS[dataset]['classes']\n","\n","    model = models.Sequential()\n","    model.add(layers.InputLayer(input_shape=dataset_shape))\n","\n","    parts = phenotype.split(',')\n","    dense_count = 0\n","\n","    for part in parts:\n","\n","        part = part.strip()\n","\n","        if 'Conv2D' in part:\n","\n","            _, filters, k_size, activation = part.split(' ')\n","            filters = int(filters)\n","            k_size = int(k_size)\n","            model.add(layers.Conv2D(filters, (k_size, k_size), activation=activation))\n","\n","        elif 'MaxPooling2D' in part:\n","\n","            _, p_size, padding = part.split(' ')\n","            p_size = int(p_size)\n","            model.add(layers.MaxPooling2D(pool_size=(p_size, p_size), padding=padding))\n","\n","        elif 'AveragePooling2D' in part:\n","\n","            _, p_size, padding = part.split(' ')\n","            p_size = int(p_size)\n","            model.add(layers.AveragePooling2D(pool_size=(p_size, p_size), padding=padding))\n","\n","        elif 'Dropout' in part:\n","\n","            _, rate = part.split(' ')\n","            rate = float(rate)\n","            model.add(layers.Dropout(rate))\n","\n","        elif 'Dense' in part:\n","\n","            _, neurons = part.split(' ')\n","            neurons = int(neurons)\n","\n","            if dense_count == 0:\n","                model.add(layers.Flatten())\n","\n","            model.add(layers.Dense(neurons))\n","\n","            dense_count += 1\n","\n","    model.add(layers.Dense(dataset_classes, activation='softmax'))\n","\n","    opt = optimizers.Adam(learning_rate=0.01)\n","\n","    return model, opt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTrTywNb9VG2"},"outputs":[],"source":["def build_diniz_model(dataset):\n","\n","    phenotype = DATASETS[dataset]['Diniz']\n","    dataset_shape = DATASETS[dataset]['shape']\n","    dataset_classes = DATASETS[dataset]['classes']\n","\n","    model = models.Sequential()\n","    model.add(layers.InputLayer(input_shape=dataset_shape))\n","\n","    nconv, npool, nfc = [int(i) for i in re.findall('\\d+', phenotype)]\n","    has_pool = 'pool' in phenotype\n","\n","    filter_size = 32\n","\n","    # Pooling\n","    for i in range(npool):\n","\n","        # Convolutions\n","        for j in range(nconv):\n","\n","            model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same'))\n","\n","            # Duplicate number of filters for each two convolutions\n","            if (((i + j) % 2) == 1): filter_size = filter_size * 2\n","\n","        # Add pooling\n","        if has_pool:\n","            model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","    model.add(layers.Flatten())\n","\n","    # fully connected\n","    for i in range(nfc):\n","        model.add(layers.Dense(256))\n","        model.add(layers.Activation('relu'))\n","\n","    model.add(layers.Dense(dataset_classes, activation='softmax'))\n","\n","    opt = optimizers.Adam(learning_rate=0.01)\n","\n","    return model, opt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vyko-aF4bglj"},"outputs":[],"source":["def build_proposal_model(dataset):\n","\n","    phenotype = DATASETS[dataset]['proposal']\n","    dataset_shape = DATASETS[dataset]['shape']\n","    dataset_classes = DATASETS[dataset]['classes']\n","\n","    model = models.Sequential()\n","    model.add(layers.InputLayer(input_shape=dataset_shape))\n","\n","    learning_rate = None\n","    filter_size = 32\n","    nconvs = 0\n","\n","    nblocks = int(phenotype[0])\n","\n","    for n in range(nblocks):\n","\n","        for block in phenotype.split(','):\n","\n","            if 'Conv' in block:\n","\n","                if nconvs == 2:\n","                    filter_size *= 2\n","                    nconvs = 0\n","\n","                model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same'))\n","\n","                if 'BNorm' in block:\n","                    model.add(layers.BatchNormalization())\n","\n","                nconvs += 1\n","\n","            if 'MaxPool' in block:\n","                model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","\n","                if 'Dropout' in block:\n","                    model.add(layers.Dropout(0.25))\n","\n","\n","    for block in phenotype.split(','):\n","\n","        if 'Flatten' in block:\n","            model.add(layers.Flatten())\n","\n","        if 'Fc' in block:\n","\n","            nfc, neurons = re.findall('\\d+', block)\n","\n","            for n in range(int(nfc)):\n","                model.add(layers.Dense(int(neurons)))\n","                model.add(layers.Activation('relu'))\n","\n","            if 'Dropout' in block:\n","                model.add(layers.Dropout(0.5))\n","\n","        if 'Softmax' in block:\n","            model.add(layers.Dense(dataset_classes, activation='softmax'))\n","\n","        if 'Lr' in block:\n","            args = re.findall('\\d+\\.\\d+', block)\n","            learning_rate = float(args[0])\n","\n","\n","    opt = optimizers.Adam(learning_rate=learning_rate)\n","\n","    return model, opt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQEKzjs78zaA"},"outputs":[],"source":["def build_cec21_model(dataset):\n","\n","    phenotype = DATASETS[dataset]['Silva']\n","    dataset_shape = DATASETS[dataset]['shape']\n","    dataset_classes = DATASETS[dataset]['classes']\n","\n","    nconv, npool, nfc, nfcneuron = [int(i) for i in re.findall('\\d+', phenotype.split('lr-')[0])]\n","    has_dropout = 'dropout' in phenotype\n","    has_batch_normalization = 'bnorm' in phenotype\n","    has_pool = 'pool' in phenotype\n","    learning_rate = float(phenotype.split('lr-')[1])\n","\n","    # number of filters\n","    filter_size = 32\n","\n","    model = models.Sequential()\n","    model.add(layers.InputLayer(input_shape=dataset_shape))\n","\n","    # Pooling\n","    for i in range(npool):\n","\n","        # Convolutions\n","        for j in range(nconv):\n","\n","            model.add(layers.Conv2D(filter_size, (3, 3), activation='relu', padding='same'))\n","\n","            # Duplicate number of filters for each two convolutions\n","            if (((i + j) % 2) == 1): filter_size = filter_size * 2\n","\n","            # Add batch normalization\n","            if has_batch_normalization:\n","                model.add(layers.BatchNormalization())\n","\n","        # Add pooling\n","        if has_pool:\n","            model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n","            # Add dropout\n","            if has_dropout:\n","                model.add(layers.Dropout(0.25))\n","\n","    model.add(layers.Flatten())\n","\n","    # fully connected\n","    for i in range(nfc):\n","        model.add(layers.Dense(nfcneuron))\n","        model.add(layers.Activation('relu'))\n","\n","    if has_dropout:\n","        model.add(layers.Dropout(0.5))\n","\n","    model.add(layers.Dense(dataset_classes, activation='softmax'))\n","\n","    opt = optimizers.Adam(learning_rate=learning_rate)\n","\n","    return model, opt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZXyrTIHEKWR"},"outputs":[],"source":["def build_cnn_model(dataset, cnn):\n","\n","  model = None\n","  # 75x75 eh o tamanho minimo que as redes disponiveis no Keras aceitam.\n","  img_w = 75\n","  img_h = 75\n","  input = Input(shape=DATASETS[dataset]['shape'])\n","  resized_images = Lambda(lambda image: resize(image, (img_w, img_h)))(input)\n","\n","  params = {\n","      'include_top': True, \n","      'weights': None, \n","      'classes': DATASETS[dataset]['classes'], \n","      'input_tensor': resized_images, \n","      'input_shape': (img_w, img_h, DATASETS[dataset]['shape'][2])\n","  }\n","\n","  if 'Inception' in cnn:\n","    model = InceptionV3(**params)\n","  elif 'ResNet' in cnn:\n","    model = ResNet50V2(**params)\n","  elif 'EfficientNet' in cnn:\n","    model = EfficientNetB1(**params)\n","  elif 'DenseNet' in cnn:\n","    model = DenseNet169(**params)\n","\n","  opt = optimizers.Adam(learning_rate=0.001)\n","\n","  return model, opt"]},{"cell_type":"markdown","metadata":{"id":"W-KjZKEH8j3a"},"source":["#Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6eGNXPReUoX"},"outputs":[],"source":["def train_model(model, dataset):\n","\n","  train_images, train_labels, validation_images, \\\n","    validation_labels, test_images, test_labels = load_dataset(dataset)\n","\n","  batch_size = 128\n","  epochs = 100\n","\n","  train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(batch_size, drop_remainder=True)\n","  validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels)).batch(batch_size, drop_remainder=True)\n","\n","  history = model.fit(train_ds,\n","          epochs=epochs, \n","          validation_data=validation_ds,\n","          verbose=1)\n","\n","  loss, accuracy, f1score = model.evaluate(test_images, test_labels, verbose=1)\n","\n","  print(accuracy, f1score)\n","\n","  return accuracy, f1score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17308,"status":"ok","timestamp":1644342154302,"user":{"displayName":"Amerson Chagas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZa0sj34fT4KS50sfZ_0Mv6sPOxixNpwn8YaRvkw=s64","userId":"13028379379499693318"},"user_tz":180},"id":"UnEp86OdlYRX","outputId":"03003cc4-20b4-4f13-b39b-ee0a926ae0c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:TPU system grpc://10.79.89.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.79.89.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.79.89.26:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.79.89.26:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}],"source":[" tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n"," tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JwD-VuR3KuI","scrolled":true,"executionInfo":{"status":"error","timestamp":1644342156138,"user_tz":180,"elapsed":1844,"user":{"displayName":"Amerson Chagas","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZa0sj34fT4KS50sfZ_0Mv6sPOxixNpwn8YaRvkw=s64","userId":"13028379379499693318"}},"colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"6fb3bd0a-8bf5-43c1-fdb1-0de9f34944a3"},"outputs":[{"output_type":"error","ename":"JSONDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-5843078c54e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRICS_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Verificando dataset e cnn:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"]}],"source":["for dataset in DATASETS:\n","\n","  for cnn in CNNS:\n","\n","    while True:\n","\n","      r = requests.get(METRICS_URL)\n","      df = pd.DataFrame.from_records(r.json())\n","\n","      print('Verificando dataset e cnn:', dataset, cnn)\n","\n","      total = len(df[(df.paper == PAPER_NAME) & (df.dataset == dataset) & (df.cnn == cnn)])\n","      remain = NUM_SAMPLES - total\n","\n","      if remain <= 0:\n","        break\n","      else:\n","        print('Ainda faltam amostras. Montando modelo.')\n","\n","        with tpu_strategy.scope():\n","          if 'Proposal' in cnn:\n","            model, opt = build_proposal_model(dataset)\n","          elif 'Lima' in cnn:\n","            model, opt = build_delima_model(dataset)\n","          elif 'Diniz' in cnn:\n","            model, opt = build_diniz_model(dataset)\n","          elif 'Assunção' in cnn:\n","            model, opt = build_assuncao_model(dataset)\n","          elif 'Silva' in cnn:\n","            model, opt = build_cec21_model(dataset)\n","          else:\n","            model, opt = build_cnn_model(dataset, cnn)\n","\n","        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', f1_score])\n","        model.summary()\n","\n","        print('Iniciando treinamento...')\n","\n","        start_time = time.time()\n","\n","        accuracy, f1score = train_model(model, dataset)\n","\n","        end_time = round(time.time() - start_time)\n","\n","        model_name = '%s-%s.h5' % (dataset, cnn)\n","        model.save(model_name)\n","        size = os.path.getsize(model_name)\n","\n","        data = {\n","            'paper': PAPER_NAME,\n","            'dataset': dataset,\n","            'cnn': cnn,\n","            'accuracy': accuracy,\n","            'f1_score': f1score,\n","            'size': size,\n","            'num_layers': len(model.layers),\n","            'num_params': model.count_params(),\n","            'time': end_time,\n","        }\n","          \n","        print(data)\n","\n","        try:\n","          r = requests.post(METRICS_URL, json=data)\n","        except BaseException as ex:\n","          print('Requests error:', ex)"]},{"cell_type":"markdown","metadata":{"id":"S65yTyMH8ngN"},"source":["#Analyse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DI_obEmlfNb"},"outputs":[],"source":["r = requests.get(METRICS_URL)\n"," \n","df = pd.DataFrame.from_records(r.json())\n","df[['accuracy', 'f1_score']] = df[['accuracy', 'f1_score']].astype(float)\n","df[['size', 'num_layers', 'num_params', 'time']] = df[['size', 'num_layers', 'num_params', 'time']].astype(float).astype(int)\n","df['size'] = df['size']/(1024*1024)\n","\n","df = df[df.paper == 'wcci']\n","df.loc[df.cnn == 'Silva et al. (2021)', 'cnn'] = 'Silva et al. (2021a)'\n","df.loc[df.cnn == 'Proposal', 'cnn'] = 'Silva et al. (2021b)'\n","df.groupby(['paper', 'dataset', 'cnn']).agg([np.mean, np.std])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIRsB-LBpn9C"},"outputs":[],"source":["objectives = ['accuracy', 'f1_score']\n","alpha = 0.05\n"," \n","print('Null hypothesis:', 'The means of the results of two or more algorithms are the same.')\n","\n","for dataset in DATASETS:\n","  \n","  data = df[df.dataset == dataset]\n","  cnns = data.cnn.unique()\n","  \n","  for objective in objectives:\n","    \n","    print('Dataset, objective:', dataset, objective)\n","    \n","    df1 = pd.DataFrame({cnn: list(data[data.cnn == cnn][objective]) for cnn in cnns})\n","    values = df1.values\n","    names = df1.columns    \n","\n","    friedman = friedmanchisquare(*values)\n","    ranks = np.array([rankdata(-p) for p in values])\n","    average_ranks = np.mean(ranks, axis = 0)\n","    \n","    cd = compute_CD(average_ranks, n=len(df1), alpha=str(alpha), test='nemenyi')\n","    \n","    print('\\t', 'null hypothesis:', 'rejected' if friedman.pvalue < alpha else 'accepted')\n","    print('\\t', 'p-value:', friedman.pvalue)\n","    print('\\t', 'ranking:', average_ranks)\n","    print('\\t', 'names:', list(names))\n","    print('\\t', 'cd:', cd)\n","    \n","    graph_ranks(average_ranks, names=names, cd=cd)\n","    # title = f'Friedman-Nemenyi (CD = {round(cd, 3)})'\n","    title = f'Dataset: {dataset}, Metric: {objective}, CD: {round(cd, 3)}'\n","    plt.title(title)\n","    plt.suptitle('p-value: {:.2e}'.format(friedman.pvalue))\n","    plt.savefig(f'/content/cd_{dataset}_{objective}.pdf', bbox_inches='tight')\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwbNzTHjrknF"},"outputs":[],"source":["!tar -cvzf plots.tar.gz /content/*.pdf"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Cópia de analise_wcci.ipynb","provenance":[{"file_id":"1MYGz6D4NJ5qTiHr4jZd3OM8uCwA7egBb","timestamp":1644341457620},{"file_id":"1d7_j3wVwezB0kxKrq56KlSmRmbKrONA7","timestamp":1642689827648},{"file_id":"1J8FCXxtqUPZOuujrsj5_n_F7-r4gbrbD","timestamp":1636380556390}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}